{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory Challenge\n",
    "## Context\n",
    "You work in the data analysis team of a very important company. On Monday, the company shares some good news with you: you just got hired by a major retail company! So, let's get prepared for a huge amount of work!\n",
    "\n",
    "Then you get to work with your team and define the following tasks to perform:   \n",
    "1. You need to start your analysis using data from the past.  \n",
    "2. You need to define a process that takes your daily data as an input and integrates it.  \n",
    "\n",
    "You are in charge of the second part, so you are provided with a sample file that you will have to read daily. To complete you task, you need the following aggregates:\n",
    "* One aggregate per store that adds up the rest of the values.\n",
    "* One aggregate per item that adds up the rest of the values.\n",
    "\n",
    "You can import the dataset `retail_sales` from Ironhack's database. \n",
    "\n",
    "## Your task\n",
    "Therefore, your process will consist of the following steps:\n",
    "1. Read the sample file that a daily process will save in your folder. \n",
    "2. Clean up the data.\n",
    "3. Create the aggregates.\n",
    "4. Write three tables in your local database: \n",
    "    - A table for the cleaned data.\n",
    "    - A table for the aggregate per store.\n",
    "    - A table for the aggregate per item.\n",
    "\n",
    "## Instructions\n",
    "* Read the csv you can find in Ironhack's database.\n",
    "* Clean the data and create the aggregates as you consider.\n",
    "* Create the tables in your local database.\n",
    "* Populate them with your process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the IronHack datbase\n",
    "driver = 'mysql+pymysql:'\n",
    "user = 'ironhacker_read'\n",
    "password = 'ir0nhack3r'\n",
    "ip = '35.239.232.23'\n",
    "database = 'retail_sales'\n",
    "\n",
    "connection_string = f'{driver}//{user}:{password}@{ip}/{database}'\n",
    "    \n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT * FROM raw_sales\n",
    "\"\"\"\n",
    "\n",
    "df_db = pd.read_sql(query, engine)\n",
    "\n",
    "df_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv file and deleting an unnecesary column\n",
    "raw_sales = pd.read_csv('raw_sales.csv')\n",
    "raw_sales.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4545 entries, 0 to 4544\n",
      "Data columns (total 5 columns):\n",
      "date            4545 non-null object\n",
      "shop_id         4545 non-null int64\n",
      "item_id         4545 non-null int64\n",
      "item_price      4545 non-null float64\n",
      "item_cnt_day    4545 non-null float64\n",
      "dtypes: float64(2), int64(2), object(1)\n",
      "memory usage: 177.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Looking for the types to change\n",
    "raw_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming quantity column\n",
    "raw_sales = raw_sales.rename( columns= {'item_cnt_day':'qty_day'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the date dtype\n",
    "raw_sales = raw_sales.astype({'date':'datetime64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4545 entries, 0 to 4544\n",
      "Data columns (total 5 columns):\n",
      "date          4545 non-null datetime64[ns]\n",
      "shop_id       4545 non-null int64\n",
      "item_id       4545 non-null int64\n",
      "item_price    4545 non-null float64\n",
      "qty_day       4545 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(2), int64(2)\n",
      "memory usage: 177.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Checking the change\n",
    "raw_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the clean data file\n",
    "raw_sales.to_csv('Clean_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the aggregate per store\n",
    "per_store = per_store.groupby(['shop_id']).agg({'item_price':'mean', 'qty_day':'sum'})\n",
    "per_store.to_csv('per_store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the aggregate per item\n",
    "per_item = raw_sales.groupby(['item_id','item_price']).agg({'qty_day':'sum'})\n",
    "per_item.to_csv('per_item.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ironhack",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
