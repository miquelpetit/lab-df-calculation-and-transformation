{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory Challenge\n",
    "## Context\n",
    "You work in the data analysis team of a very important company. On Monday, the company shares some good news with you: you just got hired by a major retail company! So, let's get prepared for a huge amount of work!\n",
    "\n",
    "Then you get to work with your team and define the following tasks to perform:   \n",
    "1. You need to start your analysis using data from the past.  \n",
    "2. You need to define a process that takes your daily data as an input and integrates it.  \n",
    "\n",
    "You are in charge of the second part, so you are provided with a sample file that you will have to read daily. To complete you task, you need the following aggregates:\n",
    "* One aggregate per store that adds up the rest of the values.\n",
    "* One aggregate per item that adds up the rest of the values.\n",
    "\n",
    "You can import the dataset `retail_sales` from Ironhack's database. \n",
    "\n",
    "## Your task\n",
    "Therefore, your process will consist of the following steps:\n",
    "1. Read the sample file that a daily process will save in your folder. \n",
    "2. Clean up the data.\n",
    "3. Create the aggregates.\n",
    "4. Write three tables in your local database: \n",
    "    - A table for the cleaned data.\n",
    "    - A table for the aggregate per store.\n",
    "    - A table for the aggregate per item.\n",
    "\n",
    "## Instructions\n",
    "* Read the csv you can find in Ironhack's database.\n",
    "* Clean the data and create the aggregates as you consider.\n",
    "* Create the tables in your local database.\n",
    "* Populate them with your process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-963739cf03a3>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-963739cf03a3>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    connection_string = f'{driver}//{user}:{password}@{ip}/{database}'\u001b[0m\n\u001b[0m                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Connecting to the IronHack datbase\n",
    "driver = 'mysql+pymysql:'\n",
    "user = 'ironhacker_read'\n",
    "password = 'ir0nhack3r'\n",
    "ip = '35.239.232.23'\n",
    "database = 'retail_sales'\n",
    "\n",
    "connection_string = f'{driver}//{user}:{password}@{ip}/{database}'\n",
    "    \n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT * FROM raw_sales\n",
    "\"\"\"\n",
    "\n",
    "df_db = pd.read_sql(query, engine)\n",
    "\n",
    "df_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv file and deleting an unnecesary column\n",
    "raw_sales = pd.read_csv('raw_sales.csv')\n",
    "raw_sales.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4545 entries, 0 to 4544\n",
      "Data columns (total 5 columns):\n",
      "date            4545 non-null object\n",
      "shop_id         4545 non-null int64\n",
      "item_id         4545 non-null int64\n",
      "item_price      4545 non-null float64\n",
      "item_cnt_day    4545 non-null float64\n",
      "dtypes: float64(2), int64(2), object(1)\n",
      "memory usage: 177.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Looking for the types to change\n",
    "raw_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming quantity column\n",
    "raw_sales = raw_sales.rename( columns= {'item_cnt_day':'qty_day'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the date dtype\n",
    "raw_sales = raw_sales.astype({'date':'datetime64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4545 entries, 0 to 4544\n",
      "Data columns (total 5 columns):\n",
      "date          4545 non-null datetime64[ns]\n",
      "shop_id       4545 non-null int64\n",
      "item_id       4545 non-null int64\n",
      "item_price    4545 non-null float64\n",
      "qty_day       4545 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(2), int64(2)\n",
      "memory usage: 177.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Checking the change\n",
    "raw_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the clean data file\n",
    "raw_sales.to_csv('Clean_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the aggregate per store\n",
    "per_store = raw_sales.groupby(['shop_id']).agg({'item_price':'mean', 'qty_day':'sum'})\n",
    "per_store.to_csv('per_store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the aggregate per item\n",
    "per_item = raw_sales.groupby(['item_id','item_price']).agg({'qty_day':'sum'})\n",
    "per_item.to_csv('per_item.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing into the database\n",
    "driver = 'mysql+pymysql:'\n",
    "user = 'root'\n",
    "password = 'miquel'\n",
    "ip = '127.0.0.1'\n",
    "database = 'df-calculation'\n",
    "\n",
    "connection_string = 'mysql+pymysql://root:miquel@127.0.0.1/df-calculation'\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "per_item.to_sql('per_item', engine)\n",
    "per_store.to_sql('per_store', engine)\n",
    "raw_sales.to_sql('raw_sales', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ironhack",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
